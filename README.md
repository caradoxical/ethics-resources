<div id="top"></div>

<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown "reference style" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

<h3 align="center">AI Ethics Resources</h3>

  <p align="center">
    A collection of media, content, and additional resources related to AI and technology ethics
  </p>
</div>

<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href="#websites">Websites</a></li>
    <li><a href="#talks">Talks</a></li>
    <li><a href="#podcasts-and-youtube-channels">Podcasts and YouTube Channels</a></li>
    <li><a href="#articles-and-white-papers">Articles and White Papers</a></li>
    <li><a href="#books">Books</a></li>
    <li><a href="#conferences-and-events">Conferences and Events</a></li>
    <li><a href="#published-research">Published Research</a></li>
    <li><a href="#contact">Contact</a></li>
  </ol>
</details>


## Websites

- [AI Ethicist](https://www.aiethicist.org/): a global repository of references and resources related to AI ethics
- [Cyberculture & Social Justice Directory](http://www.cybercultureandsocialjustice.com/): a directory of research in the broader field of cyber ethics
- [AI Ethics Course](https://aiethicscourse.org/): online course in AI ethics
- [GRACE: Global Review of AI Community Ethics](https://ojs.stanford.edu/ojs/index.php/grace/about): peer-reviewed journal from Stanford University
- [Interpetable Machine Learning: A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/): online book by Christoph Molnar

<p align="right">(<a href="#top">back to top</a>)</p>

## Talks

- [Hierarchy of KNowledge in ML & Related Fields and its Consequences](https://www.youtube.com/watch?v=OL3DowBM9uc): Timnit Gebru
- [Understanding the Limits of AI: When Algorithms Fail](https://www.youtube.com/watch?v=QqZVx6NCkPg): Timnit Gebru
- [From Ethics to Organizing: Getting Serious About AI](https://www.youtube.com/watch?v=_BzU0bD0Ics): Meredith Whittaker 
- [AI, Hate Speech, and Online Content Moderation Seminar Series](https://aiethicscourse.org/webinars/ai-hate-speech-and-online-content-moderation-seminar-series): various speakers


## Podcasts and YouTube Channels

- [Ethics in AI Podcast](https://podcasts.ox.ac.uk/series/ethics-ai)
- [The Machine Ethics Podcast](https://www.machine-ethics.net/)


<p align="right">(<a href="#top">back to top</a>)</p>

## Articles and White Papers

- AI4People's [Ethical Framework for A Good AI Society: Opportunities, Risks, Principles, and Recommendations](https://www.eismd.eu/wp-content/uploads/2019/02/Ethical-Framework-for-a-Good-AI-Society.pdf)
- [A Practical Guide to Building Ethical AI](https://hbr.org/2020/10/a-practical-guide-to-building-ethical-ai) by Reid Blackman
- [Artificial Intelligence: examples of ethical dilemmas](https://en.unesco.org/artificial-intelligence/ethics/cases)
- [Artificial Intelligence in Christian Thought and Practice](https://medium.com/ai-and-christianity/artificial-intelligence-in-christian-thought-and-practice-20ec8635a94f)

<p align="right">(<a href="#top">back to top</a>)</p>

## Books

- [The Oxford Handbook of Ethics of AI](https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780190067397.001.0001/oxfordhb-9780190067397)
- [Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way](https://philpapers.org/rec/DIGRAI) by Virginia Dignum
- [The Ethical Algorithm: The Science of Socially Aware Algorithm Design](https://www.adlibris.com/se/bok/the-ethical-algorithm-9780190948207?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gbcVOhkNH_tjphsNP5wm1KznTWXHDkCJJIlri3aHXaAfEey8rGFyxgaAjPFEALw_wcB) by Michael Kearns
- [Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy](https://www.adlibris.com/se/bok/weapons-of-math-destruction-9780141985411?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gYiPDTv9HX_sDhumMngHt7JBssR02P_TyPSrEaufGyNFn7VOHV8eKEaAgOKEALw_wcB) by Cathy O'Neil
- [Hello World: Being Human in the Age of Algorithms](https://www.adlibris.com/se/bok/hello-world-9781784163068?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gZyQO-UQTMFtg77hbTcgIIlaU7WPDeuBVAYfks0NoTTHdb6BJKeTAsaAv_3EALw_wcB) by Hannah Fry
- [Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor](https://www.adlibris.com/se/bok/automating-inequality-how-high-tech-tools-profile-police-and-punish-the-poor-9781250215789) by Virginia Eubanks
- [Artificial Unintelligence: How Computers Misunderstand the World](https://mitpress.mit.edu/books/artificial-unintelligence) by Meredith Broussard
- [Algorithms of Oppression: How Search Engines Reinforce Racism](https://nyupress.org/9781479837243/algorithms-of-oppression/) by Safiya Umoja Noble
- [Race After Technology: Abolitionist Tools for the New Jim Code](https://www.adlibris.com/se/bok/race-after-technology-9781509526406?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gZPHPHgrM_z8cxNWYd1iweWrN21s2NhYVr_8UlRF0xF2prNyOjgugEaAgLaEALw_wcB) by Ruha Benjamin
- [Technically Wrong: Sexist Apps, Biased Algorithms, and Other Threats of Toxic Tech](https://www.adlibris.com/se/bok/technically-wrong-9780393356045?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gbNvurfR3q9w33ydP9E8eQVLDJ8L84BHnAiPZOoEWHBvzxsRGZrkVQaAgt2EALw_wcB) by Sara Wachter-Boettcher

<p align="right">(<a href="#top">back to top</a>)</p>

## Conferences and Events

- AAAI/ACM conference on [Artificial Intelligence, Ethics, and Society (AIES)](https://www.aies-conference.com/2022/)
- Re-Work [AI Ethics Summit](https://www.re-work.co/events/ai-ethics-summit-2022)
- ORBIT [Women in AI & Ethics](https://www.orbit-rri.org/conference2019/)
- Artificial Intelligence Applications & Innovations [2nd Workshop on AI and Ethics](https://ifipaiai.org/2022/workshops/?gclid=Cj0KCQiAosmPBhCPARIsAHOen-NvirUKsdonNFoYmc1DtaTfgpOhUZZh51gntpmOAmFJLdQ7UJj_kTAaAttuEALw_wcB#aiethics)
- IEEE [International Symposium on Technology and Society](https://attend.ieee.org/istas-2021/)

<p align="right">(<a href="#top">back to top</a>)</p>

## Published Research

*Note: this is not an exhaustive list by any means and reflects some of my own research interests. Feel free to request additional Key Topics tags!*

| Authors | Title | Year | Key Topics |
| ------- | ----- | ---- | ---------- |
| Aroyo et al. | [Data Excellence for AI: Why Should You Care](https://arxiv.org/ftp/arxiv/papers/2111/2111.10391.pdf) | 2021 | `Data` |
| Aroyo & Welty | [Truth is a Lie: Crowd Truth and the Seven Myths of Human Annotation](https://ojs.aaai.org/index.php/aimagazine/article/view/2564) | 2015 | `Data` `NLP` |
| Bartl et al. | [Unmasking Contextual Stereotypes: Measuring and Mitigating BERT's Gender Bias](https://arxiv.org/pdf/2010.14534.pdf) | 2020 | `NLP` `LLM` `Bias Mitigation` | 
| Basta et al. | [Evaluating the Underlying Gender Bias in Contextualized Word Embeddings](https://aclanthology.org/W19-3805.pdf) | 2019 | `NLP` `LLM` | 
| Bender et al. | [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://dl.acm.org/doi/10.1145/3442188.3445922) | 2021 | `NLP` `LLM` |
| Davis & Osoba | [Privacy Preservation in the Age of Big Data](https://www.rand.org/pubs/working_papers/WR1161.html) | 2016 | `Privacy` `Data` |
| Dillon, S. | [The Eliza Effect and Its Dangers: From Demystification to Gender Critique](https://www.repository.cam.ac.uk/bitstream/handle/1810/304211/Dillon%20The%20Eliza%20Effect%20JCR.pdf?sequence=1&isAllowed=n) | 2020 | `Virtual Assistants` `Feminism` |
| Fazelpour & De-Arteaga | [Diversity in Sociotechnical Machine Learning Systems](https://arxiv.org/pdf/2107.09163.pdf) | 2021 | `Algorithmic Fairness` | 
| Gebru et al. | [Datasheets for Datasets](https://arxiv.org/pdf/1803.09010.pdf) | 2021 | `Data` `XAI` |
| Gonen & Goldberg | [Lipstick on a Pig: Debiasing Methods Cover up Systemic Gender Biases in Word Embeddings But Do Not Remove Them](https://arxiv.org/pdf/1903.03862.pdf) | 2019 | `NLP` `LLM` |
| Guo & Caliskan | [Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases](https://dl.acm.org/doi/pdf/10.1145/3461702.3462536) | 2021 | `NLP` `LLM` |
| Hanna et al. | [Towards a Critical Race Methodology in Algorithmic Fairness](https://arxiv.org/pdf/1912.03593.pdf) | 2019 | `Critical Race Theory` `Algorithmic Fairness` |
| Hardt et al. | [Equality of Opportunity in Supervised Learning](https://arxiv.org/pdf/1610.02413.pdf) | 2016 | `Supervised Learning` `Algorithmic Fairness` |
| Hutchinson et al. | [Towards Accountability for Machine Learning Datasets: Practices from Sofftware Engineering and Infrastructure](https://arxiv.org/pdf/2010.13561.pdf) | 2021 | `Data` |
| Jacobs & Wallach | [Measurement and Fairness](https://arxiv.org/pdf/1912.05511.pdf) | 2021 | `Algorithmic Fairness` | 
| Jobin et al. | [The global landscape of AI ethics](https://www.nature.com/articles/s42256-019-0088-2) | 2019 | `Literature Review` |
| Kurita et al. | [Measuring Bias in Contextualized Word Representations](https://aclanthology.org/W19-3823.pdf) | 2019 | `NLP` `LLM` |
| Lee, M. | [Understanding Perceptions of Algorithmic Decisions: Fairness, Trust, and Emotion in Response to Algorithmic Management](https://journals.sagepub.com/doi/full/10.1177/2053951718756684) | 2018 | `Algorithmic Fairness` |
| Liu et al. | [Privacy and Security Issues in Deep Learning: A Survey](https://ieeexplore.ieee.org/document/9294026) | 2021 | `Privacy` | 
| Matthews et al. | [Gender Bias in Natural Language Processing Across Human Languages](https://aclanthology.org/2021.trustnlp-1.6.pdf) | 2021 | `NLP` `LLM` | 
| McGregor, S. | [Preventing Repeated Real World AI Failures by Cataloging Incidents: The AI Incident Database](https://arxiv.org/pdf/2011.08512.pdf) | 2020 | `Datasets`|
| Mitchell et al. | [Model Cards for Model Reporting](https://arxiv.org/pdf/1810.03993.pdf) | 2019 | `Data` `XAI` | 
| Nadeem et al. | [StereoSet: Measuring stereotypical bias in pretrained language models](https://arxiv.org/pdf/2004.09456.pdf) | 2020 | `NLP` `LLM` `Datasets` |
| Nangia et al. | [CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models](https://arxiv.org/pdf/2010.00133.pdf) | 2020 | `NLP` `LLM` `Datasets` |
| Selbst et al. | [Fairness and Abstraction in Sociotechnical Systems](https://dl.acm.org/doi/10.1145/3287560.3287598) | 2019 | `Algorithmic Fairness` |
| Suresh et al. | [A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle](https://arxiv.org/pdf/1901.10002.pdf) | 2021 | `Algorithmic Fairness` 
| Webster et al. | [Measuring and Reducing Gendered Correlations in Pre-trained Models](https://arxiv.org/pdf/2010.06032.pdf) | 2020 | `NLP` `Bias Mitigation` `LLM` |
| Zhang & Zhao | [Online Decision Trees with Fairness](https://arxiv.org/pdf/2010.08146.pdf) | 2020 | `Algorithmic Fairness` | 


<p align="right">(<a href="#top">back to top</a>)</p>

## Contact

Jesse Shanahan - [@enceladosaurus](https://twitter.com/enceladosaurus) - jess.c.shanahan@gmail.com

<p align="right">(<a href="#top">back to top</a>)</p>


<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/enceladosaurus/ethics-resources.svg?style=for-the-badge
[contributors-url]: https://github.com/enceladosaurus/ethics-resources/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/enceladosaurus/ethics-resources.svg?style=for-the-badge
[forks-url]: https://github.com/enceladosaurus/ethics-resources/network/members
[stars-shield]: https://img.shields.io/github/stars/enceladosaurus/ethics-resources.svg?style=for-the-badge
[stars-url]: https://github.com/enceladosaurus/ethics-resources/stargazers
[issues-shield]: https://img.shields.io/github/issues/enceladosaurus/ethics-resources.svg?style=for-the-badge
[issues-url]: https://github.com/enceladosaurus/ethics-resources/issues
